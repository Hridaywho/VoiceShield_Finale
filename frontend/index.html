<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Shield: AI-Powered Aggression Detector</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <script src="https://cdn.socket.io/4.7.2/socket.io.min.js"></script>
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
            margin: 0;
            padding: 20px;
            box-sizing: border-box;
            color: #e2e8f0;
        }
        .container {
            background: rgba(30, 41, 59, 0.95);
            backdrop-filter: blur(20px);
            border: 1px solid rgba(148, 163, 184, 0.3);
            border-radius: 1.5rem;
            box-shadow: 0 20px 25px -5px rgba(0, 0, 0, 0.5), 0 10px 10px -5px rgba(0, 0, 0, 0.3);
            padding: 2rem;
            max-width: 1000px;
            width: 100%;
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 1.5rem;
        }
        .headline {
            background: linear-gradient(90deg, #ffffff 0%, #93c5fd 50%, #60a5fa 100%);
            -webkit-background-clip: text;
            background-clip: text;
            color: transparent;
        }
        .video-container {
            position: relative;
            width: 100%;
            max-width: 640px;
            border-radius: 1rem;
            overflow: hidden;
            background-color: #000;
            box-shadow: 0 10px 30px rgba(2, 6, 23, 0.7), inset 0 0 0 1px rgba(148, 163, 184, 0.1);
        }
        video {
            width: 100%;
            height: auto;
            display: block;
            /* This will mirror the video feed, which is more intuitive for users */
            transform: scaleX(-1);
        }
        canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }
        .score-display {
            display: flex;
            gap: 1rem;
            margin-top: 1rem;
            justify-content: center;
            flex-wrap: wrap;
        }
        .score-card {
            background-color: rgba(51, 65, 85, 0.8);
            border: 1px solid rgba(148, 163, 184, 0.3);
            border-radius: 0.5rem;
            padding: 0.75rem;
            text-align: center;
            min-width: 100px;
        }
        .score-card h4 {
            margin: 0 0 0.25rem 0;
            font-size: 0.875rem;
            color: #94a3b8;
        }
        .score-card .score {
            font-size: 1.25rem;
            font-weight: 600;
            color: #e2e8f0;
        }
        .emotions-display {
            width: 100%;
            max-width: 400px;
            background-color: rgba(51, 65, 85, 0.8);
            border: 1px solid rgba(148, 163, 184, 0.3);
            border-radius: 0.75rem;
            padding: 1rem;
            margin-top: 1rem;
            box-shadow: inset 0 1px 3px 0 rgba(0, 0, 0, 0.3);
        }
        .ai-analysis {
            width: 100%;
            max-width: 400px;
            background-color: rgba(30, 58, 138, 0.3);
            border: 1px solid rgba(59, 130, 246, 0.5);
            border-radius: 0.75rem;
            padding: 1rem;
            margin-top: 1rem;
        }
        .audio-visualizer {
            width: 100%;
            max-width: 400px;
            height: 60px;
            background: linear-gradient(180deg, rgba(30, 41, 59, 0.9), rgba(15, 23, 42, 0.9));
            border: 1px solid rgba(148, 163, 184, 0.3);
            border-radius: 0.75rem;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-top: 1rem;
        }
        .audio-bars {
            display: flex;
            gap: 2px;
            align-items: end;
            height: 40px;
        }
        .audio-bar {
            width: 4px;
            background-color: #3b82f6;
            border-radius: 2px;
            transition: height 0.1s ease;
        }
        .status-indicator {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            margin-top: 1rem;
        }
        .status-dot {
            width: 10px;
            height: 10px;
            border-radius: 9999px;
            background-color: #ef4444; /* disconnected */
            box-shadow: 0 0 0 2px rgba(239, 68, 68, 0.2);
        }
        .status-dot.connected {
            background-color: #10b981;
            box-shadow: 0 0 0 2px rgba(16, 185, 129, 0.2);
        }
        .status-dot.recording {
            background-color: #f59e0b;
            box-shadow: 0 0 0 2px rgba(245, 158, 11, 0.2);
            animation: pulse 1.5s ease-in-out infinite;
        }
        .button-group {
            display: flex;
            gap: 1rem;
            margin-top: 1rem;
            flex-wrap: wrap;
            justify-content: center;
        }
        .btn {
            padding: 0.75rem 1.5rem;
            border-radius: 0.75rem;
            font-weight: 600;
            cursor: pointer;
            transition: background-color 0.2s ease-in-out, transform 0.1s ease-in-out;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
            border: 1px solid rgba(148, 163, 184, 0.2);
        }
        .btn-primary {
            background-color: #3b82f6;
            color: white;
        }
        .btn-primary:hover {
            background-color: #2563eb;
            transform: translateY(-1px);
        }
        .btn-danger {
            background-color: #ef4444;
            color: white;
        }
        .btn-danger:hover {
            background-color: #dc2626;
            transform: translateY(-1px);
        }
        .btn-success {
            background-color: #10b981;
            color: white;
        }
        .btn-success:hover {
            background-color: #059669;
            transform: translateY(-1px);
        }
        .message-box {
            background-color: rgba(59, 130, 246, 0.2);
            color: #93c5fd;
            border: 1px solid rgba(59, 130, 246, 0.3);
            padding: 1rem;
            border-radius: 0.75rem;
            margin-top: 1rem;
            width: 100%;
            max-width: 400px;
            text-align: center;
            font-size: 0.9rem;
            display: none;
        }
        .message-box.show {
            display: block;
        }

        /* Anger threshold slider styling */
        input[type="range"]::-webkit-slider-thumb {
            -webkit-appearance: none;
            appearance: none;
            width: 18px;
            height: 18px;
            background: #ef4444;
            border-radius: 50%;
            cursor: pointer;
            border: 2px solid rgba(255,255,255,0.2);
            transition: all 0.2s ease;
        }
        
        input[type="range"]::-webkit-slider-thumb:hover {
            background: #dc2626;
            transform: scale(1.1);
        }

        #aggressionPopup {
            transition: opacity 0.3s ease;
        }
        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="absolute top-4 left-4 z-10">
            <a href="intro.html" class="inline-flex items-center space-x-2 px-4 py-2 rounded-full shadow-lg transition-all duration-300 hover:shadow-xl" style="background: rgba(2,6,23,0.6); backdrop-filter: blur(10px); border: 1px solid rgba(148,163,184,0.25); color: #e2e8f0;">
                <i class="fas fa-arrow-left" style="color:#93c5fd;"></i>
                <span class="font-medium">Back to Intro</span>
            </a>
        </div>
        
        <h1 class="text-3xl font-bold text-center headline">Voice Shield: AI-Powered Aggression Detector</h1>
        <p class="text-slate-300 text-center">
            Advanced emotion detection using facial expressions and voice analysis.
            <br>Please grant camera and microphone access to begin.
        </p>
        <div class="video-container">
            <video id="videoInput" autoplay muted playsinline></video>
            <canvas id="overlayCanvas"></canvas>
        </div>
        <div id="voiceDetectionTab" class="emotions-display" style="margin-top:1rem;max-width:400px;">
            <strong class="text-slate-200">Voice Detection:</strong> <span id="voiceDetectionText" class="text-slate-300">-</span>
        </div>
        <div class="audio-visualizer">
            <div id="audioBars" class="audio-bars"></div>
        </div>
        <div class="score-display">
            <div class="score-card">
                <h4>Facial Score</h4>
                <div id="facialScore" class="score">0%</div>
            </div>
            <div class="score-card">
                <h4>Voice Score</h4>
                <div id="voiceScore" class="score">0%</div>
            </div>
            <div class="score-card">
                <h4>Combined Score</h4>
                <div id="combinedScore" class="score">0%</div>
            </div>
            <div class="score-card">
                <h4>Faces Detected</h4>
                <div id="faceCount" class="score">0</div>
            </div>
        </div>
        <div id="emotionsDisplay" class="emotions-display">
            <div style="display:flex;justify-content:space-between;align-items:center;">
                <p><strong class="text-slate-200">Facial Emotion Probabilities:</strong></p>
                <span id="multiFaceIndicator" style="display:none;color:#f87171;font-weight:600;font-size:0.95em;">Multiple Faces Detected</span>
            </div>
            <p id="emotionNeutral" class="text-slate-300">Neutral: 0%</p>
            <p id="emotionHappy" class="text-slate-300">Happy: 0%</p>
            <p id="emotionSad" class="text-slate-300">Sad: 0%</p>
            <p id="emotionAngry" class="text-slate-300">Angry: 0%</p>
            <p id="emotionFearful" class="text-slate-300">Fearful: 0%</p>
            <p id="emotionDisgusted" class="text-slate-300">Disgusted: 0%</p>
            <p id="emotionSurprised" class="text-slate-300">Surprised: 0%</p>
        </div>
        <div id="aiAnalysis" class="ai-analysis" style="display: none;">
            <h3 class="text-slate-200">AI Analysis Results</h3>
            <p id="aiVoiceEmotion" class="text-slate-300">Voice Emotion: Analyzing...</p>
            <p id="aiConfidence" class="text-slate-300">Confidence: 0%</p>
            <p id="aiRecommendation" class="text-slate-300">Recommendation: No action needed</p>
        </div>
        <div class="status-indicator">
            <div id="statusDot" class="status-dot"></div>
            <span id="statusText" class="text-slate-300">Disconnected</span>
            <span id="listeningIndicator" style="display:none;margin-left:10px;color:#60a5fa;font-weight:600;">ðŸŽ¤ Listening...</span>
        </div>
        <div class="button-group">
            <button id="startButton" class="btn btn-primary">Start Detection</button>
            <button id="stopButton" class="btn btn-danger" disabled>Stop Detection</button>
            <button id="connectButton" class="btn btn-success">Connect to AI Server</button>
        </div>
        
        <div class="w-full max-w-sm mt-4 p-4 rounded-lg bg-slate-700/50 border border-slate-600">
            <label for="angerThreshold" class="block text-sm font-medium text-slate-300">
                Anger Alert Threshold: <span id="angerThresholdValue" class="font-bold text-blue-400">50%</span>
            </label>
            <input id="angerThreshold" type="range" min="10" max="90" value="50" class="w-full h-2 bg-slate-600 rounded-lg appearance-none cursor-pointer mt-2">
        </div>
        
        <div id="loadingMessage" class="message-box show">
            Loading facial recognition models... Please wait.
        </div>
        <div id="errorMessage" class="message-box">
            An error occurred. Please ensure camera and microphone access is granted.
        </div>
        <div id="aggressionPopup" style="display:none;position:fixed;top:0;left:0;width:100vw;height:100vh;background:rgba(0,0,0,0.7);z-index:1000;justify-content:center;align-items:center;opacity:0;">
            <div style="background:rgba(30,41,59,0.95);border:1px solid rgba(239,68,68,0.5);padding:2rem 3rem;border-radius:1rem;box-shadow:0 4px 24px rgba(0,0,0,0.5);text-align:center;max-width:90%;width:400px;">
                <div class="text-red-500 text-5xl mb-4">
                    <i class="fas fa-exclamation-triangle"></i>
                </div>
                <h3 style="font-size:1.5rem;font-weight:700;color:#f87171;margin-bottom:1rem;">Aggression Detected</h3>
                <p style="color:#e2e8f0;font-size:1.1rem;margin-bottom:1rem;">High levels of anger detected in the environment</p>
                <div style="background:rgba(239,68,68,0.1);border:1px solid rgba(239,68,68,0.2);padding:0.5rem;border-radius:0.5rem;margin-bottom:1rem;">
                    <p style="color:#fca5a5;font-size:0.9rem;">Current Anger Level: <span id="popupAngerLevel">0%</span></p>
                </div>
                <button onclick="hideAggressionPopup()" style="background:#ef4444;color:white;padding:0.5rem 1.5rem;border-radius:0.5rem;font-weight:600;transition:all 0.2s ease;">
                    Acknowledge
                </button>
            </div>
        </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>

    <script>
        // DOM Elements
        const videoInput = document.getElementById('videoInput');
        const overlayCanvas = document.getElementById('overlayCanvas');
        const emotionsDisplay = document.getElementById('emotionsDisplay');
        const emotionNeutral = document.getElementById('emotionNeutral');
        const emotionHappy = document.getElementById('emotionHappy');
        const emotionSad = document.getElementById('emotionSad');
        const emotionAngry = document.getElementById('emotionAngry');
        const emotionFearful = document.getElementById('emotionFearful');
        const emotionDisgusted = document.getElementById('emotionDisgusted');
        const emotionSurprised = document.getElementById('emotionSurprised');
        const startButton = document.getElementById('startButton');
        const stopButton = document.getElementById('stopButton');
        const connectButton = document.getElementById('connectButton');
        const loadingMessage = document.getElementById('loadingMessage');
        const errorMessage = document.getElementById('errorMessage');
        const statusDot = document.getElementById('statusDot');
        const statusText = document.getElementById('statusText');
        const audioBars = document.getElementById('audioBars');
        const aiAnalysis = document.getElementById('aiAnalysis');
        const aiVoiceEmotion = document.getElementById('aiVoiceEmotion');
        const aiConfidence = document.getElementById('aiConfidence');
        const aiRecommendation = document.getElementById('aiRecommendation');
        const facialScore = document.getElementById('facialScore');
        const voiceScore = document.getElementById('voiceScore');
        const combinedScore = document.getElementById('combinedScore');
        const faceCountDisplay = document.getElementById('faceCount');
        const multiFaceIndicator = document.getElementById('multiFaceIndicator');
        const aggressionPopup = document.getElementById('aggressionPopup');
        const listeningIndicator = document.getElementById('listeningIndicator');
        const voiceDetectionText = document.getElementById('voiceDetectionText');

        // State variables
        let mediaRecorder = null;
        let audioStream = null;
        let stream = null;
        let intervalId = null;
        let modelsLoaded = false;
        let socket = null;
        let isConnected = false;
        let isRecording = false;
        let audioContext = null;
        let analyser = null;
        let microphone = null;
        let dataArray = null;
        let animationId = null;

        // Face count smoothing (mode of last N frames)
        const FACE_COUNT_WINDOW = 15;
        let faceCountHistory = [];
        function pushFaceCount(count) {
            faceCountHistory.push(count);
            if (faceCountHistory.length > FACE_COUNT_WINDOW) faceCountHistory.shift();
        }
        function getStableFaceCount() {
            if (faceCountHistory.length === 0) return 0;
            const freq = new Map();
            faceCountHistory.forEach(c => freq.set(c, (freq.get(c) || 0) + 1));
            let best = faceCountHistory[faceCountHistory.length - 1];
            let bestN = 0;
            for (const [k, v] of freq.entries()) {
                if (v > bestN) { bestN = v; best = k; }
            }
            return best;
        }

        // Configuration
        const MODELS_CDN_PATH = 'https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model/';
        const SOCKET_URL = 'http://localhost:10000';
        const AUDIO_SAMPLE_RATE = 16000;

        // Create audio visualizer bars
        function createAudioBars() {
            audioBars.innerHTML = '';
            for (let i = 0; i < 20; i++) {
                const bar = document.createElement('div');
                bar.className = 'audio-bar';
                bar.style.height = '2px';
                audioBars.appendChild(bar);
            }
        }

        // Update audio visualizer
        function updateAudioVisualizer() {
            if (!analyser || !dataArray) return;
            analyser.getByteFrequencyData(dataArray);
            const bars = audioBars.children;
            const step = Math.floor(dataArray.length / bars.length);
            for (let i = 0; i < bars.length; i++) {
                const value = dataArray[i * step];
                const height = (value / 255) * 40;
                bars[i].style.height = `${Math.max(2, height)}px`;
            }
            animationId = requestAnimationFrame(updateAudioVisualizer);
        }

        // Initialize audio processing
        async function initializeAudio() {
            try {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 256;
                dataArray = new Uint8Array(analyser.frequencyBinCount);
                if (audioStream) {
                    microphone = audioContext.createMediaStreamSource(audioStream);
                    microphone.connect(analyser);
                    updateAudioVisualizer();
                }
            } catch (error) {
                console.error('Error initializing audio:', error);
            }
        }

        // Send audio data to AI server
        function sendAudioData(audioData) {
            if (socket && socket.connected) {
                socket.emit('audio', { data: audioData, timestamp: Date.now() });
            }
        }

        // Connect to AI server using Socket.IO
        async function connectToAIServer() {
            try {
                socket = io(SOCKET_URL);
                socket.on('connect', () => {
                    isConnected = true;
                    statusDot.classList.add('connected');
                    statusText.textContent = 'Connected to AI Server';
                    connectButton.disabled = true;
                    hideMessageBoxes();
                });
                socket.on('disconnect', () => {
                    isConnected = false;
                    statusDot.classList.remove('connected');
                    statusText.textContent = 'Disconnected';
                    connectButton.disabled = false;
                });
                socket.on('emotion_analysis', (data) => {
                    handleAIAnalysis(data);
                });
                socket.on('error', (data) => {
                    console.error('Server error:', data.message);
                    showMessageBox(data.message, 'error');
                });
            } catch (error) {
                console.error('Error connecting to AI server:', error);
                showMessageBox('Failed to connect to AI server.', 'error');
            }
        }

        // Send facial analysis data to AI server
        function sendFacialData(detections) {
            if (socket && socket.connected && detections.length > 0) {
                detections.forEach((detection, index) => {
                    socket.emit('facial_analysis', {
                        expressions: detection.expressions,
                        timestamp: Date.now(),
                        faceIndex: index
                    });
                });
            }
        }

        // Update emotion probabilities display
        function updateEmotionProbabilities(detections) {
            const emotions = { neutral: 0, happy: 0, sad: 0, angry: 0, fearful: 0, disgusted: 0, surprised: 0 };
            if (detections.length > 0) {
                detections.forEach(detection => {
                    const expressions = detection.expressions;
                    for (const emotion in expressions) {
                        if (emotions.hasOwnProperty(emotion)) {
                            emotions[emotion] += expressions[emotion];
                        }
                    }
                });
                for (const emotion in emotions) {
                    const percent = (emotions[emotion] / detections.length) * 100;
                    emotions[emotion] = Math.round(percent * 10) / 10;
                }
                const angryScore = emotions.angry;
                const fearfulScore = emotions.fearful;
                const disgustedScore = emotions.disgusted;
                const localAggressionScore = Math.round(((angryScore * 0.4) + (fearfulScore * 0.3) + (disgustedScore * 0.2)) * 10) / 10;
                facialScore.textContent = `${localAggressionScore.toFixed(1)}%`;
            }
            emotionNeutral.textContent = `Neutral: ${emotions.neutral.toFixed(1)}%`;
            emotionHappy.textContent = `Happy: ${emotions.happy.toFixed(1)}%`;
            emotionSad.textContent = `Sad: ${emotions.sad.toFixed(1)}%`;
            emotionAngry.textContent = `Angry: ${emotions.angry.toFixed(1)}%`;
            emotionFearful.textContent = `Fearful: ${emotions.fearful.toFixed(1)}%`;
            emotionDisgusted.textContent = `Disgusted: ${emotions.disgusted.toFixed(1)}%`;
            emotionSurprised.textContent = `Surprised: ${emotions.surprised.toFixed(1)}%`;
        }

        // Handle AI analysis results
        function handleAIAnalysis(data) {
            aiAnalysis.style.display = 'block';
            const voiceConfidence = data.confidence || 0;
            const voiceEmotion = data.voiceEmotion || 'Unknown';
            const confidenceThreshold = 60;
            if (voiceConfidence >= confidenceThreshold) {
                aiVoiceEmotion.textContent = `Voice Emotion: ${voiceEmotion}`;
                voiceDetectionText.textContent = voiceEmotion;
                listeningIndicator.style.display = 'inline';
            } else {
                aiVoiceEmotion.textContent = `Voice Emotion: Uncertain`;
                voiceDetectionText.textContent = 'Uncertain';
                listeningIndicator.style.display = 'none';
            }
            aiConfidence.textContent = `Confidence: ${voiceConfidence}%`;
            aiRecommendation.textContent = `Recommendation: ${data.recommendation || 'No action needed'}`;
            const facial = typeof data.facialScore === 'number' ? data.facialScore : 0;
            const audio = typeof data.audioScore === 'number' ? data.audioScore : 0;
            const combined = typeof data.combinedScore === 'number' ? data.combinedScore : 0;
            facialScore.textContent = `${facial.toFixed(1)}%`;
            voiceScore.textContent = `${audio.toFixed(1)}%`;
            combinedScore.textContent = `${combined.toFixed(1)}%`;
            if (data.faceCount !== undefined) {
                faceCountDisplay.textContent = data.faceCount;
                multiFaceIndicator.style.display = data.faceCount > 1 ? 'block' : 'none';
            }
            checkAngerThreshold(data);
        }

        // Message box functions
        function showMessageBox(message, type) {
            loadingMessage.classList.remove('show');
            errorMessage.classList.remove('show');
            let box = type === 'error' ? errorMessage : loadingMessage;
            if (type === 'error') {
                box.style.background = 'rgba(239, 68, 68, 0.2)';
                box.style.borderColor = 'rgba(239, 68, 68, 0.3)';
                box.style.color = '#fca5a5';
            } else if (type === 'success') {
                box.style.background = 'rgba(16, 185, 129, 0.2)';
                box.style.borderColor = 'rgba(16, 185, 129, 0.3)';
                box.style.color = '#6ee7b7';
            } else {
                box.style.background = 'rgba(59, 130, 246, 0.2)';
                box.style.borderColor = 'rgba(59, 130, 246, 0.3)';
                box.style.color = '#93c5fd';
            }
            box.textContent = message;
            box.classList.add('show');
        }

        function hideMessageBoxes() {
            loadingMessage.classList.remove('show');
            errorMessage.classList.remove('show');
        }

        // Load face-api.js models
        async function loadModels() {
            showMessageBox('Loading facial recognition models... Please wait.', 'loading');
            try {
                await faceapi.nets.ssdMobilenetv1.loadFromUri(MODELS_CDN_PATH);
                await faceapi.nets.faceExpressionNet.loadFromUri(MODELS_CDN_PATH);
                await faceapi.nets.faceLandmark68Net.loadFromUri(MODELS_CDN_PATH);
                modelsLoaded = true;
                startButton.disabled = false;
                showMessageBox('Models loaded successfully! You can now start detection.', 'success');
            } catch (error) {
                console.error('Error loading models:', error);
                showMessageBox('Failed to load models. Check internet connection and console.', 'error');
                startButton.disabled = true;
            }
        }

        // Start detection (camera + microphone)
        async function startDetection() {
            try {
                if (!modelsLoaded) return showMessageBox('Models are still loading. Please wait.', 'loading');
                if (!socket || !socket.connected) return showMessageBox('Please connect to AI server first.', 'error');

                showMessageBox('Requesting camera and microphone access...', 'loading');
                stream = await navigator.mediaDevices.getUserMedia({
                    video: { width: { ideal: 640 }, height: { ideal: 480 }, facingMode: 'user' },
                    audio: { sampleRate: AUDIO_SAMPLE_RATE, channelCount: 1, echoCancellation: true, noiseSuppression: true }
                });

                videoInput.srcObject = stream;
                audioStream = new MediaStream(stream.getAudioTracks());
                await initializeAudio();

                mediaRecorder = new MediaRecorder(audioStream);
                mediaRecorder.ondataavailable = e => {
                    if (e.data.size > 0) {
                        const reader = new FileReader();
                        reader.onloadend = () => sendAudioData(reader.result.split(',')[1]);
                        reader.readAsDataURL(e.data);
                    }
                };
                mediaRecorder.start(1000);

                videoInput.onloadedmetadata = () => {
                    const displaySize = { width: videoInput.videoWidth, height: videoInput.videoHeight };
                    faceapi.matchDimensions(overlayCanvas, displaySize);

                    // LATEST CHANGE: This interval block is updated to fix inverted text
                    intervalId = setInterval(async () => {
                        const detections = await faceapi.detectAllFaces(videoInput, new faceapi.SsdMobilenetv1Options({ minConfidence: 0.5 }))
                            .withFaceLandmarks()
                            .withFaceExpressions();
                        
                        const resizedDetections = faceapi.resizeResults(detections, displaySize);
                        const ctx = overlayCanvas.getContext('2d');
                        ctx.clearRect(0, 0, overlayCanvas.width, overlayCanvas.height);

                        // Save the context state before global mirror transformation
                        ctx.save();

                        // Mirror the entire canvas to correctly draw bounding boxes on a mirrored video feed
                        ctx.translate(overlayCanvas.width, 0);
                        ctx.scale(-1, 1);

                        resizedDetections.forEach(detection => {
                            const box = detection.detection.box;
                            const expressions = detection.expressions;

                            // Find the dominant emotion with the highest score
                            const dominantEmotion = Object.keys(expressions).reduce((a, b) => expressions[a] > expressions[b] ? a : b);
                            const score = expressions[dominantEmotion];
                            const text = `${dominantEmotion} (${Math.round(score * 100)}%)`;
                            const textX = box.x;
                            const textY = box.y > 20 ? box.y - 10 : box.y + box.height + 20;

                            // Draw the blue bounding box
                            ctx.strokeStyle = '#3b82f6';
                            ctx.lineWidth = 2;
                            ctx.strokeRect(box.x, box.y, box.width, box.height);
                            
                            // --- Counter-transform for text drawing to make it readable ---
                            ctx.save();
                            ctx.translate(textX, textY);
                            ctx.scale(-1, 1);
                            ctx.fillStyle = '#60a5fa';
                            ctx.font = '16px Inter';
                            ctx.textAlign = 'right'; 
                            ctx.fillText(text, 0, 0);
                            ctx.restore();
                            // --- End counter-transform for text ---
                        });

                        // Restore the canvas to its original state
                        ctx.restore();

                        // The rest of your logic remains the same
                        updateEmotionProbabilities(resizedDetections);
                        sendFacialData(resizedDetections);
                        pushFaceCount(resizedDetections.length);
                        faceCountDisplay.textContent = getStableFaceCount();

                    }, 200);
                };

                isRecording = true;
                statusDot.classList.add('recording');
                startButton.disabled = true;
                stopButton.disabled = false;
                hideMessageBoxes();

            } catch (error) {
                console.error('Error in startDetection:', error);
                let msg = 'Error starting detection.';
                if (error.name === 'NotAllowedError') msg = 'Camera/mic access denied.';
                if (error.name === 'NotFoundError') msg = 'No camera/mic found.';
                showMessageBox(msg, 'error');
                startButton.disabled = false;
            }
        }

        // Stop detection
        function stopDetection() {
            if (intervalId) clearInterval(intervalId);
            if (mediaRecorder) mediaRecorder.stop();
            if (stream) stream.getTracks().forEach(track => track.stop());
            videoInput.srcObject = null;
            overlayCanvas.getContext('2d').clearRect(0, 0, overlayCanvas.width, overlayCanvas.height);
            ['facialScore', 'voiceScore', 'combinedScore'].forEach(id => document.getElementById(id).textContent = '0%');
            faceCountDisplay.textContent = '0';
            isRecording = false;
            statusDot.classList.remove('recording');
            startButton.disabled = false;
            stopButton.disabled = true;
            hideMessageBoxes();
        }

        // Event listeners
        startButton.addEventListener('click', startDetection);
        stopButton.addEventListener('click', stopDetection);
        connectButton.addEventListener('click', connectToAIServer);

        // Anger threshold functionality
        const angerThreshold = document.getElementById('angerThreshold');
        const angerThresholdValue = document.getElementById('angerThresholdValue');
        const popupAngerLevel = document.getElementById('popupAngerLevel');
        let currentThreshold = 50;
        let popupTimeout = null;

        if (angerThreshold) {
            angerThreshold.addEventListener('input', (e) => {
                currentThreshold = parseInt(e.target.value);
                angerThresholdValue.textContent = `${currentThreshold}%`;
            });
        }

        function showAggressionPopup(angerLevel) {
            const popup = document.getElementById('aggressionPopup');
            popupAngerLevel.textContent = `${Math.round(angerLevel)}%`;
            popup.style.display = 'flex';
            setTimeout(() => { popup.style.opacity = '1'; }, 10);
        }

        function hideAggressionPopup() {
            const popup = document.getElementById('aggressionPopup');
            popup.style.opacity = '0';
            setTimeout(() => { popup.style.display = 'none'; }, 300);
        }

        // Pop-up only triggers from FACIAL anger
        function checkAngerThreshold(data) {
            const facialAnger = data.emotionBars?.angry || 0;
            if (facialAnger >= currentThreshold) {
                socket.emit('anger_detected', {
                    angerLevel: facialAnger,
                    threshold: currentThreshold,
                    timestamp: new Date().toISOString()
                });
                if (popupTimeout) clearTimeout(popupTimeout);
                showAggressionPopup(facialAnger);
                popupTimeout = setTimeout(hideAggressionPopup, 5000);
            }
        }

        // Initialize
        window.onload = () => {
            loadModels();
            createAudioBars();
        };
    </script>
</body>
</html>